# -*- coding: utf-8 -*-
"""00_preprocessing_sathvick.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1PlAeKuhgEyNZFXmBAJv38t315sRusr2Q
"""

import nltk
nltk.download('stopwords')
nltk.download('punkt')
nltk.download('wordnet')
nltk.download('omw-1.4')
from nltk.corpus import stopwords

import pandas as pd
import re
import nltk
from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer
import matplotlib.pyplot as plt
from wordcloud import WordCloud
import plotly.express as px

df = pd.read_csv('/content/training1600000.csv',encoding = "ISO-8859-1",header=None)

df.columns = ["polarity",'id','date','query','user','tweet']
df

"""# Missing Values"""

df.isnull().sum()

"""## Text Cleaning"""

def clean_text(text):
    text = str(text).lower()
    text = re.sub(r'http\S+',' ',text)
    text = re.sub('[^a-zA-Z]',' ',text)
    text = word_tokenize(text)
    text = [item for item in text if item not in stop_words]
    text = [lemma.lemmatize(w) for w in text]
    text = [i for i in text if len(i)>2]
    text = ' '.join(text)
    return text

stop_words = set(stopwords.words('english'))
lemma = WordNetLemmatizer()

df_new = df[0:100000]

df_neg = df[1500000:1600000]



df['clean_tweet'] = df['tweet'].apply(clean_text)

"""# Data Visualization

# WordCloud
"""

plt.figure(figsize=(20,20))
STOPWORDS = set(stopwords.words('english'))
wordcloud = WordCloud(min_font_size=5, max_words=300, width=1600 , height=800 , stopwords=STOPWORDS).generate(str(" ".join(df_new.clean_tweet)))
plt.axis('off')
plt.imshow(wordcloud)
plt.show()

"""# WordCloud for positive tweets(polarity =4)




"""

plt.figure(figsize=(20,20))
STOPWORDS = set(stopwords.words('english'))
wordcloud = WordCloud(min_font_size=5, max_words=300, width=1600 , height=800 , stopwords=STOPWORDS).generate(str(" ".join(df[df['polarity'] == 4][0:100000].tweet)))
plt.axis('off')
plt.imshow(wordcloud)
plt.show()

"""## Wordcloud for Negative Tweets(polarity=0)"""

plt.figure(figsize=(20,20))
STOPWORDS = set(stopwords.words('english'))
wordcloud = WordCloud(min_font_size=5, max_words=300, width=1600 , height=800 , stopwords=STOPWORDS).generate(str(" ".join(df[df['polarity'] == 0][0:100000].tweet)))
plt.axis('off')
plt.imshow(wordcloud)
plt.show()

"""# Top 10 words"""

top10_word = df_new[0:100000].clean_tweet.str.split(expand=True).stack().value_counts()[:10]

fig = px.bar(top10_word, color=top10_word.values, color_continuous_scale=px.colors.sequential.RdPu, custom_data=[top10_word.values])
fig.update_traces(hovertemplate='Count: %{customdata[0]}')

fig.update_layout(title="Top 10 words",
                  template='simple_white',
                  hovermode='x unified')
fig.show()